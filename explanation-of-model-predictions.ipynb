{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explanation of machine learning models predictions \n",
    "---\n",
    "Anton Kulesh, Data Scientist  \n",
    "Datathon  \n",
    "Minsk, July 2019 \n",
    "\n",
    "---\n",
    "In this notebook we play with different tools for interpretatitng of machine learning models. We solve **binary classification** problem, try to predict probability of **customer churn** and **explain predictions** of the [black-box](https://en.wikipedia.org/wiki/Black_box) model. As a black-box model we use gradient boosting on decision trees ([XGBoost](https://xgboost.readthedocs.io/en/latest/)).\n",
    "\n",
    "### Local explanation \n",
    "    - LIME\n",
    "    - ELI5\n",
    "    - SHAP\n",
    "    - InterpretML\n",
    "### Global feature importance   \n",
    "#### model-specific (for tree-based ensembles)\n",
    "    - Gain\n",
    "    - Splits count\n",
    "    - Coverage   \n",
    "#### model-agnostic   \n",
    "    - Permutation\n",
    "    - mean(|shap_values|)\n",
    "    \n",
    "   \n",
    " *Ok, let's go!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# LIME\n",
    "import lime\n",
    "from lime.lime_tabular import LimeTabularExplainer\n",
    "from lime import submodular_pick\n",
    "#\n",
    "# ELI5\n",
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "#\n",
    "# SHAP\n",
    "import shap\n",
    "#\n",
    "# InterpretML\n",
    "import interpret\n",
    "from interpret.data import ClassHistogram\n",
    "from interpret.perf import ROC\n",
    "from interpret.blackbox import ShapKernel, LimeTabular, MorrisSensitivity, PartialDependence\n",
    "from interpret.glassbox import ExplainableBoostingClassifier, LogisticRegression\n",
    "#\n",
    "# Data manipulation and modeling\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, classification_report\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "#\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style=\"white\")\n",
    "%matplotlib inline\n",
    "\n",
    "# For plotting nice shap /graphs\n",
    "shap.initjs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 1. Data\n",
    "# Telco Customer Churn\n",
    "\n",
    "#### Data description\n",
    "Each row represents a customer, each column contains customer's attributes. The data set includes information about:\n",
    "1. Customers who left within the last month – the column is called ``Churn`` (target variable)\n",
    "2. Services that each customer has signed up for – phone (``PhoneService``), multiple lines (``MultipleLines``), internet (``InternetService``), online security (``OnlineSecurity``), online backup (``OnlineBackup``), device protection (``DeviceProtection``), tech support (``TechSupport``), streaming TV (``StreamingTV``) and movies (``StreamingMovies``)  \n",
    "3. Customer account information – how long they’ve been a customer (``tenure``), contract (``Contract``), payment method (``PaymentMethod``), paperless billing (``PaperlessBilling``), monthly charges (``MonthlyCharges``), and total charges (``TotalCharges``)\n",
    "4. Demographic info about customers – ``gender``, age range (``SeniorCitizen``), and if they have partners (``Partner``) and dependents (``Dependents``)\n",
    "\n",
    "\n",
    "#### Link to the source:\n",
    "https://www.kaggle.com/blastchar/telco-customer-churn  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation\n",
    "After loading the data we'll:\n",
    "* remove useless columns\n",
    "* fill missing values\n",
    "* encode binary variables\n",
    "* encode categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = \"./data/telco-customer-churn.zip\"\n",
    "data = pd.read_csv(path_to_data, compression=\"zip\")\n",
    "\n",
    "del data[\"customerID\"]\n",
    "data['TotalCharges'] = data['TotalCharges'].replace(\" \", 0).astype('float32')\n",
    "data['gender'] = data['gender'].apply(lambda x: 1 if x == \"Female\" else 0)\n",
    "\n",
    "bool_columns = ['Partner', 'Dependents', 'PhoneService',\n",
    "                'OnlineSecurity', 'OnlineBackup', 'DeviceProtection',\n",
    "                'TechSupport', 'StreamingTV', 'StreamingMovies',\n",
    "                'PaperlessBilling', 'Churn'\n",
    "               ]\n",
    "for col in bool_columns:\n",
    "    data[col] = data[col].apply(lambda x: 1 if x == \"Yes\" else 0)\n",
    "\n",
    "columns = data.columns.to_list()[:-1]\n",
    "categorical_names = ['MultipleLines', 'InternetService', 'Contract', 'PaymentMethod']\n",
    "categorical_columns = [columns.index(col) for col in categorical_names]\n",
    "encoder = OrdinalEncoder()\n",
    "data[categorical_names] = encoder.fit_transform(data[categorical_names])\n",
    "categorical_names_dict = {col: list(values) for col, values in zip(categorical_columns, encoder.categories_)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorical_decode(data, idx):\n",
    "    return dict(zip(\n",
    "            categorical_names,\n",
    "            encoder.inverse_transform(\n",
    "            data[idx, categorical_columns].reshape(1, -1))[0]\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the prepared data sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the target variable distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"Churn\"\n",
    "ax = sns.catplot(y=target, kind=\"count\", data=data)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe some class imbalance. But it's not big problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[target].value_counts(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We omit feature engineering phase, as this is redundant in context of our goals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make dataset\n",
    "Let's simply split out data to ``train`` (70% for model training) and ``test`` (30% for model validation) sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = data.copy()\n",
    "y_data = X_data.pop(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_data.values, y_data.values, test_size=0.3, random_state=42)\n",
    "print(\"Train size: {}\".format(X_train.shape))\n",
    "print(\"Test size: {}\".format(X_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 2. Training\n",
    "For modeling we use simple and powerful gradient boosting classifier. This is our black box model that we want to explain. Let's train our model on given dataset and calculate quality metric ([ROC AUC](https://developers.google.com/machine-learning/crash-course/classification/roc-and-auc)). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = XGBClassifier(max_depth=3, n_estimators=50, importance_type=\"gain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train)\n",
    "y_proba = clf.predict_proba(X_test)[:, 1]\n",
    "print(\"ROC-AUC: {}\".format(roc_auc_score(y_test, y_proba)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Single Tree\n",
    "Let's take a closer look at the first tree from our ensemble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "booster = clf.get_booster()\n",
    "original_feature_names = booster.feature_names\n",
    "booster.feature_names = columns\n",
    "print(booster.get_dump()[0])\n",
    "booster.feature_names = original_feature_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model performance results\n",
    "We put our predictions and true labels in one table. Then we convert predicted probabilities into binary labels (threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(np.vstack((y_test, y_proba)).T, columns=[\"y_test\", \"y_proba\"])\n",
    "results[\"y_test\"] = results[\"y_test\"].astype(\"bool\")\n",
    "results[\"y_pred\"] = results[\"y_proba\"] >= 0.5\n",
    "results[\"error\"] = results['y_proba'] - results['y_test']\n",
    "results[\"abs_error\"] = abs(results['y_proba'] - results['y_test'])\n",
    "results.sort_values('error', ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's at the classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(results[\"y_test\"], results[\"y_pred\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's compare performance of our \"black box\" with [\"dummy\" model](https://scikit-learn.org/stable/modules/generated/sklearn.dummy.DummyClassifier.html) (generates predictions by respecting the training set's class distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy = DummyClassifier()\n",
    "dummy.fit(X_train, y_train)\n",
    "y_proba_dummy = dummy.predict_proba(X_test)[:, 1]\n",
    "print(\"ROC-AUC: {}\".format(roc_auc_score(y_test, y_proba_dummy)))\n",
    "print(classification_report(y_test, y_proba_dummy >= 0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not bad! We can see that model shows quite promising results even without applying smart feature engineering technique and model parameters tuning. So let's try to give some explanations and crack our black box open."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Local Interpretability\n",
    "Most part of this notebook is devoted to the explanation of individual samples (local interpretability of the model).  \n",
    "\n",
    "We start with the [LIME](https://arxiv.org/abs/1602.04938) algorithm ([original](https://github.com/marcotcr/lime) implementation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## lime\n",
    "[lime package](https://github.com/marcotcr/lime) provides working with models which have different input types:\n",
    "* ``LimeTabularExplainer`` -- working with tabular data\n",
    "* ``RecurrentTabularExplainer`` -- working with time series\n",
    "* ``LimeTextExplainer`` -- working with text data inputs\n",
    "* ``LimeImageExplainer`` -- explains predictions on images\n",
    "\n",
    "For our tast we use ``LimeTabularExplainer``. Let's create *explainer* (``LimeTabularExplainer`` class object) and get explanation for some examples (``explainer.explain_instance``)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_explainer(data, **kwargs):\n",
    "    explainer = LimeTabularExplainer(\n",
    "        data, feature_names=columns, categorical_features=categorical_columns, \n",
    "        categorical_names=categorical_names_dict, class_names=[\"no churn\", \"churn\"],\n",
    "        discretize_continuous=True, **kwargs)\n",
    "\n",
    "    return explainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of \"no churn\"\n",
    "Let's look at the top 5 features and their contributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 2\n",
    "explainer = create_explainer(X_train, verbose=True, kernel_width=None)\n",
    "\n",
    "exp = explainer.explain_instance(X_test[i], predict_fn=clf.predict_proba, num_samples=1000,\n",
    "                                 num_features=10, model_regressor=None)\n",
    "print(\"Predicted_label: [{}]\".format(int(y_proba[i] >= 0.5)))\n",
    "print(\"True_label: [{}]\".format(y_test[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_df = pd.DataFrame(exp.as_list(), columns=['feature_value', 'feature_contribution'])\n",
    "exp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's sum weights and compare with ``Prediction_local`` above. We can see that it's exactly the same value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_df.feature_contribution.sum() + exp.intercept[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detailed explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.show_in_notebook(show_table=True, show_all=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature contributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.as_pyplot_figure();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descriptive statistics of numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_columns = ['tenure', 'MonthlyCharges', 'TotalCharges']\n",
    "X_data[num_columns].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also save our explanation as html file\n",
    "\n",
    "``exp.save_to_file(\"./data/demo_0.html)``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of \"churn\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "exp = explainer.explain_instance(X_test[i], predict_fn=clf.predict_proba, num_samples=1000,\n",
    "                                 num_features=10, model_regressor=None)\n",
    "print(\"Predicted_label: [{}]\".format(int(y_proba[i] >= 0.5)))\n",
    "print(\"True_label: [{}]\".format(y_test[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.as_pyplot_figure();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submodular Pick\n",
    "This technique allows us to select a set of representative instances from our dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "explainer = create_explainer(X_train)\n",
    "%time sp_explanations = submodular_pick.SubmodularPick(explainer, X_test, clf.predict_proba, method=\"full\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i, explanation in zip(sp_explanations.V, sp_explanations.sp_explanations):\n",
    "    print(\"\\nExplanation #{}\".format(i))\n",
    "    print(\"\\nIntercept: {}\".format(explanation.intercept))\n",
    "    print(\"\\nLocal_prediction: {}\".format(explanation.local_pred[0]))\n",
    "    print(\"\\nModel_prediction: {}\".format(y_proba[i]))\n",
    "    print(\"\\nTrue_label: {}\".format(y_test[i]))\n",
    "    explanation.show_in_notebook();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe that for some examples local prediction has high residuals. It looks like a weakness of LIME approach. Maybe it related with neibourhoods definition and local kernel settings. So, in general, we can try to pick optimal parameters for our explainer, but it out-of-scope this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### See also\n",
    "* More examples [here](https://github.com/marcotcr/lime/tree/master/doc/notebooks)\n",
    "* Nice LIME algorithm explanation by C. Molner: [5.7 Local Surrogate (LIME)](https://christophm.github.io/interpretable-ml-book/lime.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ELI5\n",
    "Next tool is [ELI5](https://eli5.readthedocs.io/en/latest/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation of a single prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "eli5.show_prediction(clf, X_test[i],\n",
    "                     feature_names=columns,\n",
    "                     show_feature_values=True,\n",
    "                     show=[\"targets\",\n",
    "                           \"feature_importances\",\n",
    "                           \"description\",\n",
    "                           \"method\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eli5.explain_prediction_df(clf, X_test[i], feature_names=columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eli5.show_weights(clf, feature_names=columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's just a nice way to show model's feature importances. XGBoost by default uses ``gain``, that is the average gain of the feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.from_records(\n",
    "    data=zip(columns, clf.feature_importances_),\n",
    "    columns=[\"name\", \"importance\"]).sort_values(by=\"importance\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ELI5 also allows us to use ``Permutation Importance`` technique, and we will mention it in \"Global Interpretability\" section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SHAP\n",
    "SHAP (SHapley Additive exPlanations) is a unified approach to explain the output of any machine learning model. SHAP connects game theory with local explanations, uniting several previous methods and representing the only possible consistent and locally accurate additive feature attribution method based on expectations.\n",
    "\n",
    "see repo for details: https://github.com/slundberg/shap  \n",
    "## TreeSHAP\n",
    "Efficient implementation of SHAP for tree models: https://arxiv.org/pdf/1802.03888.pdf."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create *explainer* and calculate SHAP values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.TreeExplainer(clf, X_train, model_output=\"probability\", feature_dependence=\"independent\")\n",
    "%time shap_values = explainer.shap_values(X_test[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SHAP values of the first sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Model prediction: {}\".format(y_proba[0]))\n",
    "print(\"Sum of SHAP values + base values: {}\".format(sum(shap_values[0]) + explainer.expected_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Expected value: {}\".format(explainer.expected_value))\n",
    "print(\"Average prediction: {}\".format(clf.predict_proba(X_train)[:, 1].mean(0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation of a single prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "shap.force_plot(base_value=explainer.expected_value, shap_values=shap_values[i,:], features=X_test[i,:], feature_names=columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation of a multiple predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.force_plot(explainer.expected_value, shap_values[:500,:], X_test[:500,:], feature_names=columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary Plot\n",
    "```\n",
    "[..] To get an overview of which features are most important for a model we can plot the SHAP values of every feature for every sample. The plot below sorts features by the sum of SHAP value magnitudes over all samples, and uses SHAP values to show the distribution of the impacts each feature has on the model output. The color represents the feature value (red high, blue low).\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, X_test[:500], feature_names=columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary Plot for \"Churn\" class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "churn_mask = y_test[:500] == 1\n",
    "no_churn_mask = y_test[:500] == 0\n",
    "print(\"Customers in churn: {}\".format(sum(churn_mask)))\n",
    "print(\"Customers is alive: {}\".format(sum(no_churn_mask)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values[churn_mask], X_test[:500][churn_mask], feature_names=columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary plot for \"No Churn\" class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values[no_churn_mask], X_test[:500][no_churn_mask], feature_names=columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, X_test, plot_type=\"bar\", feature_names=columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependence Plots\n",
    "```\n",
    "[..] SHAP dependence plots show the effect of a single feature across the whole dataset. They plot a feature's value vs. the SHAP value of that feature across many samples. SHAP dependence plots are similar to partial dependence plots, but account for the interaction effects present in the features, and are only defined in regions of the input space supported by data. The vertical dispersion of SHAP values at a single feature value is driven by interaction effects, and another feature is chosen for coloring to highlight possible interactions.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we create dependence plots for most important 7 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "feature_importance = pd.DataFrame.from_records(\n",
    "    data=list(zip(columns, np.mean(np.abs(shap_values), axis=0))), \n",
    "    columns=[\"name\", \"importance\"]\n",
    ")\n",
    "feature_importance.sort_values(by=\"importance\", ascending=False, inplace=True)\n",
    "\n",
    "n_top = 7\n",
    "for col in feature_importance.name[:n_top]:\n",
    "    shap.dependence_plot(col, shap_values, X_test[:500], feature_names=columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KernelSHAP\n",
    "```\n",
    "[..] Kernel SHAP is a method that uses a special weighted linear regression\n",
    "to compute the importance of each feature. The computed importance values\n",
    "are Shapley values from game theory and also coefficents from a local linear\n",
    "regression.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lambda x: clf.predict_proba(x)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use apply [kmeans](https://en.wikipedia.org/wiki/K-means_clustering) to reduce input dimensions, get approximation of original data and use it as a background dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = shap.kmeans(X_train, 100)\n",
    "kernel_explainer = shap.KernelExplainer(model, data, feature_names=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Expected values (KernalExplainer): {}\".format(kernel_explainer.expected_value))\n",
    "print(\"Expected values (TreeExplainer): {}\".format(explainer.expected_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time shap_values_kernel = kernel_explainer.shap_values(X_test[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KernelExplainer values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values_kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.force_plot(base_value=float(kernel_explainer.expected_value),\n",
    "                shap_values=shap_values_kernel,\n",
    "                feature_names=columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TreeExplainer values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values[0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.force_plot(base_value=explainer.expected_value,\n",
    "                shap_values=shap_values[0],\n",
    "                feature_names=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(shap_values[0, :], shap_values_kernel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%time shap_values_kernel = kernel_explainer.shap_values(X_test[:10, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### See also\n",
    "* More examples: https://github.com/slundberg/shap/tree/master/notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## InterpretML\n",
    "Microsoft Research has developed an algorithm called the Explainable Boosting Machine ([EBM](https://www.microsoft.com/en-us/research/wp-content/uploads/2017/06/KDD2015FinalDraftIntelligibleModels4HealthCare_igt143e-caruanaA.pdf)) which has both high accuracy and intelligibility. EBM uses modern machine learning techniques like bagging and boosting to breathe new life into traditional GAMs (Generalized Additive Models). This makes them as accurate as random forests and gradient boosted trees, and also enhances their intelligibility and editability.\n",
    "\n",
    "This tool looks very promising. It has nice functionality but is still under development.\n",
    "\n",
    "see repo: https://github.com/microsoft/interpret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "hist = ClassHistogram(feature_names=columns).explain_data(X_train, y_train, name=\"EDA\")\n",
    "interpret.show(hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train \"White Box\" Model\n",
    "### Exaplainable Boosting Machine\n",
    "[Link to paper](https://www.microsoft.com/en-us/research/wp-content/uploads/2017/06/KDD2015FinalDraftIntelligibleModels4HealthCare_igt143e-caruanaA.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ebc = ExplainableBoostingClassifier(feature_names=columns, random_state=42)\n",
    "%time ebc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation of a single prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "ebc_local = ebc.explain_local(X_test[:n], y_test[:n], name=\"EBC\")\n",
    "interpret.show(ebc_local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "categorical_decode(X_test, i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ebc_global = ebc.explain_global(name=\"EBC\")\n",
    "interpret.show(ebc_global)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ebc_roc_curve = interpret.perf.ROC(\n",
    "    predict_fn=ebc.predict_proba).explain_perf(X_test, y_test, name='Churn detection (EBC)')\n",
    "interpret.show(ebc_roc_curve)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All in one place"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add one more model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(feature_names=columns)\n",
    "lr.fit(X_train, y_train)\n",
    "lr_global = lr.explain_global(name=\"LR\")\n",
    "lr_local = lr.explain_local(X_test[:n], y_test[:n], name=\"LR\")\n",
    "lr_roc_curve = interpret.perf.ROC(\n",
    "    predict_fn=lr.predict_proba).explain_perf(X_test, y_test, name='Churn detection (LR)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the entire picture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "interpret.show(\n",
    "    explanation=[hist, ebc_roc_curve, ebc_global, ebc_local, lr_roc_curve, lr_global, lr_local],\n",
    "    share_tables=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LIME and SHAP support"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation of tabular data using LIME (``LimeTabular``)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "lime_explainer = LimeTabular(predict_fn=clf.predict_proba,\n",
    "                             data=X_train,\n",
    "                             feature_names=columns,\n",
    "                             random_state=42\n",
    "                            )\n",
    "%time lime_local = lime_explainer.explain_local(X_test[:n], y_test[:n], name='LIME (LimeTabular)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently interpret supports only ``ShapKernel`` (aka ``KernelShap``)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "background_data = shap.kmeans(X_train, 100).data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "shap_explainer = ShapKernel(predict_fn=clf.predict_proba, data=background_data, feature_names=columns)\n",
    "shap_local = shap_explainer.explain_local(X_test[:n], y_test[:n], name='SHAP (ShapKernel)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpret.show([lime_local, shap_local], share_tables=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Global Interpretability\n",
    "# Feature Importance techniques\n",
    "Here we shortly look at some technique for assessing global feature importance.\n",
    "\n",
    "First, let's define some helpful functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_importances_table(feature_importances_array, feature_names=None, n_top=None):\n",
    "    if feature_names is None:\n",
    "        feature_names = X_data.columns\n",
    "    if n_top is None:\n",
    "        n_top = len(feature_importances_array)\n",
    "    feature_importances = list(zip(feature_names, feature_importances_array))\n",
    "    feature_importances = pd.DataFrame.from_records(\n",
    "        feature_importances, columns=[\"feature_name\", \"importance\"])\n",
    "    feature_importances.sort_values(\"importance\", inplace=True, ascending=True)\n",
    "    feature_importances = feature_importances[-n_top:]\n",
    "    return feature_importances\n",
    "\n",
    "\n",
    "def show_feature_importances(feature_importances, feature_names=None, n_top=None):\n",
    "    if not isinstance(feature_importances, pd.DataFrame):\n",
    "        feature_importances = feature_importances_table(\n",
    "            feature_importances, feature_names=feature_names, n_top=n_top)\n",
    "        \n",
    "    ax = feature_importances.plot.barh(\n",
    "        x=\"feature_name\", y=\"importance\", figsize=(10, 8),\n",
    "        fontsize=16, color='green', alpha=0.8)\n",
    "    ax.grid()\n",
    "    plt.title(\"Feature importances\", fontsize=20)\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "def calculate_feature_saturation(feature_importances, model=None,\n",
    "                                 feature_names=None, n_top=None, show=True, label=None):\n",
    "    if model is None:\n",
    "        model = XGBClassifier(max_depth=3, n_estimators=50)\n",
    "    if not isinstance(feature_importances, pd.DataFrame):\n",
    "        feature_importances = feature_importances_table(\n",
    "            feature_importances, feature_names=feature_names, n_top=n_top)\n",
    "    \n",
    "    score = {}\n",
    "    for i in range(1, len(feature_importances)):\n",
    "        features = feature_importances[-i:][\"feature_name\"]\n",
    "        column_mask = X_data.columns.isin(features)\n",
    "        model.fit(X_train[:, column_mask], y_train)\n",
    "        y_proba = model.predict_proba(X_test[:, column_mask])[:, 1]\n",
    "        score[i] = roc_auc_score(y_test, y_proba)\n",
    "    return score\n",
    "\n",
    "\n",
    "def show_feature_saturation(scores, labels, colors, show=True):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    for score, label, color in zip(scores, labels, colors):\n",
    "        plt.plot(score.keys(), score.values(), \"-*\", color=color, label=label)\n",
    "        plt.title(\"Dependence of the model score on the number of features\")\n",
    "        plt.xlabel(\"Numbel of features\")\n",
    "        plt.ylabel(\"ROC AUC\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Permutation Importances\n",
    "* Read more about this technique in [ELI5 docs](https://eli5.readthedocs.io/en/latest/blackbox/permutation_importance.html#eli5-permutation-importance )\n",
    "* Here some info from Kaggle tutorial: https://www.kaggle.com/dansbecker/permutation-importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perm = PermutationImportance(clf, random_state=42).fit(X_train, y_train)\n",
    "eli5.show_weights(perm, feature_names=X_data.columns.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances_by_permutation = np.abs(perm.feature_importances_)\n",
    "show_feature_importances(feature_importances_by_permutation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SHAP Values (``Tree SHAP``)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.TreeExplainer(clf, X_train, model_output=\"probability\", feature_dependence=\"independent\")\n",
    "%time shap_values = explainer.shap_values(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances_by_shap = np.mean(np.abs(shap_values), axis=0)\n",
    "show_feature_importances(feature_importances_by_shap, n_top=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Morris method\n",
    "See for details: https://en.wikipedia.org/wiki/Morris_method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensitivity = MorrisSensitivity(predict_fn=clf.predict_proba, data=X_train, feature_names=columns)\n",
    "sensitivity_global = sensitivity.explain_global(name=\"Global Sensitivity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances_by_moris = sensitivity_global.data()[\"scores\"]\n",
    "show_feature_importances(feature_importances_by_moris)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gain\n",
    "The average training loss reduction gained when using a feature for splitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = XGBClassifier(max_depth=3, n_estimators=50, importance_type=\"gain\")\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "feature_importances_by_gain = clf.feature_importances_\n",
    "show_feature_importances(feature_importances_by_gain, n_top=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weight\n",
    "The number of times a feature is used to split the data across all trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = XGBClassifier(max_depth=3, n_estimators=50, importance_type=\"weight\")\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "feature_importances_by_weight = clf.feature_importances_\n",
    "show_feature_importances(feature_importances_by_weight, n_top=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cover\n",
    "The number of times a feature is used to split the data across all trees weighted by the number of training data points that go through those splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = XGBClassifier(max_depth=3, n_estimators=50, importance_type=\"cover\")\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "feature_importances_by_cover = clf.feature_importances_\n",
    "show_feature_importances(feature_importances_by_cover, n_top=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = [calculate_feature_saturation(fi)\n",
    "          for fi in [\n",
    "              feature_importances_by_permutation,\n",
    "              feature_importances_by_shap,\n",
    "              feature_importances_by_moris,\n",
    "              feature_importances_by_gain,\n",
    "              feature_importances_by_weight,\n",
    "              feature_importances_by_cover,\n",
    "          ]\n",
    "         ]\n",
    "labels = [\"permutation\", \"shap\", \"moris\", \"gain\", \"weight\", \"cover\"]\n",
    "colors = [\"red\", \"blue\", \"green\", \"yellow\", \"pink\", \"grey\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_feature_saturation(scores, labels=labels, colors=colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Wide range of the notebooks with **examples of using SHAP**: https://github.com/slundberg/shap/tree/master/notebooks  \n",
    "* More LIME examples: https://github.com/marcotcr/lime/tree/master/doc/notebooks\n",
    "* Examples of using ELI5: https://github.com/TeamHG-Memex/eli5/tree/master/notebooks  \n",
    "* ELI5's documentation: https://eli5.readthedocs.io/en/latest/index.html  \n",
    "* InterpretML repo: https://github.com/microsoft/interpret\n",
    "* Scott Lundberg. Interpretable Machine Learning with XGBoost: https://towardsdatascience.com/interpretable-machine-learning-with-xgboost-9ec80d148d27\n",
    "* Scott Lundberg, Su-In Lee. A Unified Approach to Interpreting ModelPredictions: https://arxiv.org/pdf/1705.07874.pdf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:datathon]",
   "language": "python",
   "name": "conda-env-datathon-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
